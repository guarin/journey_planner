{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict delays for every scheduled connection\n",
    "\n",
    "In this notebook, we provide schedule connections with an uncertainty parameter for prediciting possible delays. In other words, we map the static public transport network with the delay analysis in order to obtain a meaningful and accurate predictive model. The notebook is structured as follows: \n",
    "\n",
    "*   **[Start Spark](#spark)** \n",
    "*   **[Merge connections and probabilities](#merge)**  \n",
    "*   **[Get predictive model](#predictive)** \n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'spark'></a>\n",
    "### 1. Start Spark\n",
    "\n",
    "We will be using a Spark Session for performing different transformations and actions on dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%configure -f\n",
    "{\n",
    "    \"conf\": {\n",
    "        \"spark.app.name\": \"wow\",\n",
    "        \"spark.driver.memory\": '8g',\n",
    "        'spark.driver.maxResultSize': '6g',\n",
    "        \"spark.executor.memory\": \"2g\",\n",
    "        \"spark.executor.instances\": \"64\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>8421</td><td>application_1589299642358_2953</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://iccluster044.iccluster.epfl.ch:8088/proxy/application_1589299642358_2953/\">Link</a></td><td><a target=\"_blank\" href=\"http://iccluster072.iccluster.epfl.ch:8042/node/containerlogs/container_e06_1589299642358_2953_01_000001/ebouille\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7fa6ab43e290>"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'merge'></a>\n",
    "### 2. Merge connections and probabilities\n",
    "\n",
    "We load our two dataframes: the \"ideal\" schedule for the connections and the one containing the delay probability. We are able to join them thanks to the prevously performed transformations. However, we have to be careful , given that some connection # for some connections we have no line specific probabilities, so we have to add transport-type probabilities as backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "id_connections = spark.read.orc('/user/datavirus/id_connections.orc').repartition(150, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probability = spark.read.orc('/user/datavirus/probability.orc').repartition(150, 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "probability_connections = (\n",
    "    id_connections\n",
    "    .join(probability, ['id', 'station_id', 'arrival_time_minute'], how='left_outer')\n",
    "    .select(\n",
    "        id_connections.stop_sequence,\n",
    "        id_connections.route_type,\n",
    "        id_connections.arrival_time_hour,\n",
    "        id_connections.produkt_id,\n",
    "        id_connections.start_id,\n",
    "        id_connections.start_time,\n",
    "        id_connections.trip_id,\n",
    "        probability.transport_type,\n",
    "        probability.line_text,\n",
    "        id_connections.stop_time,\n",
    "        id_connections.stop_id,\n",
    "        probability.delay_probability,\n",
    "        probability.delay_parameter\n",
    "    )\n",
    ")\n",
    "\n",
    "probability_connections.write.format('orc').save('/user/datavirus/probability_connections_new.orc', mode='overwrite')\n",
    "#probability_connections = spark.read.orc('/user/datavirus/probability_connections_new.orc').alias('probability_connections')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# probability back-up\n",
    "transport_probability = spark.read.orc('/user/datavirus/transport_probability.orc').alias('transport_probability')\n",
    "transport_probability = (\n",
    "    transport_probability\n",
    "    .withColumn('arrival_time_hour', transport_probability.ankunftszeit_hour)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'predictive'></a>\n",
    "### 3. Get predictive model\n",
    "\n",
    "At last, we can obtain the final connection dataframe with the probability parameters included. This will help us predict the future delay of any connection incorporated in our transport network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "connections = (\n",
    "    probability_connections\n",
    "    .join(transport_probability, ['produkt_id', 'arrival_time_hour'])\n",
    "    .select(\n",
    "        probability_connections.stop_sequence,\n",
    "        probability_connections.route_type,\n",
    "        probability_connections.start_id,\n",
    "        probability_connections.start_time,\n",
    "        probability_connections.trip_id,\n",
    "        probability_connections.produkt_id.alias('transport_type'),\n",
    "        probability_connections.line_text,\n",
    "        probability_connections.stop_time,\n",
    "        probability_connections.stop_id,\n",
    "        f.when(\n",
    "            f.col('probability_connections.delay_probability').isNotNull(),\n",
    "            f.col('probability_connections.delay_probability')\n",
    "        ).otherwise(\n",
    "            f.col('transport_probability.transport_delay_probability')\n",
    "        ).alias('delay_probability'),\n",
    "        f.when(f.col('probability_connections.delay_parameter').isNotNull(),\n",
    "              f.col('probability_connections.delay_parameter')\n",
    "        ).otherwise(\n",
    "            f.col('transport_probability.transport_delay_parameter')\n",
    "        ).alias('delay_parameter')\n",
    "    )\n",
    "    .orderBy([probability_connections.stop_time.desc(), probability_connections.stop_sequence.desc()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "connections.write.format('csv').save('/user/datavirus/connections.csv', mode='overwrite')\n",
    "#connections = spark.read.csv('/user/datavirus/connections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+-------+--------+-----------------------+---+----+--------+-------+------------------+--------------------+\n",
      "|_c0|_c1|_c2    |_c3     |_c4                    |_c5|_c6 |_c7     |_c8    |_c9               |_c10                |\n",
      "+---+---+-------+--------+-----------------------+---+----+--------+-------+------------------+--------------------+\n",
      "|2  |700|8502209|10:05:00|9.TA.30-170-Y-j19-1.1.H|bus|null|10:05:00|8502209|0.9193866847990115|0.011589134124321832|\n",
      "|2  |700|8502771|10:05:00|392.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|493.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|360.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|345.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|439.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|224.TA.26-235-j19-1.4.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|390.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|410.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2  |700|8502771|10:05:00|450.TA.26-235-j19-1.5.R|bus|235 |10:05:00|8502771|0.9159136766383016|0.013732196842403623|\n",
      "+---+---+-------+--------+-----------------------+---+----+--------+-------+------------------+--------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "connections.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "connections.write.csv('/user/datavirus/connections_test.csv', header=True, mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = spark.read.csv('/user/datavirus/connections_test.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------+--------+----------+-----------------------+--------------+---------+---------+-------+------------------+--------------------+\n",
      "|stop_sequence|route_type|start_id|start_time|trip_id                |transport_type|line_text|stop_time|stop_id|delay_probability |delay_parameter     |\n",
      "+-------------+----------+--------+----------+-----------------------+--------------+---------+---------+-------+------------------+--------------------+\n",
      "|2            |700       |8502209 |10:05:00  |9.TA.30-170-Y-j19-1.1.H|bus           |null     |10:05:00 |8502209|0.9193866847990115|0.011589134124321832|\n",
      "|2            |700       |8502771 |10:05:00  |392.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |493.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |360.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |345.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |439.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |224.TA.26-235-j19-1.4.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |390.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |410.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "|2            |700       |8502771 |10:05:00  |450.TA.26-235-j19-1.5.R|bus           |235      |10:05:00 |8502771|0.9159136766383016|0.013732196842403623|\n",
      "+-------------+----------+--------+----------+-----------------------+--------------+---------+---------+-------+------------------+--------------------+\n",
      "only showing top 10 rows"
     ]
    }
   ],
   "source": [
    "c.show(10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
