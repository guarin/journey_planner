{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from hdfs3 import HDFileSystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfs = HDFileSystem(host='hdfs://iccluster044.iccluster.epfl.ch', port=8020, user='ebouille')\n",
    "def read_csv(path, parts=None, **kwargs):\n",
    "    dfs = []\n",
    "    file_paths = [file_path for file_path in hdfs.ls(path) if file_path.endswith('.csv')]\n",
    "    if parts:\n",
    "        file_paths = file_paths[:parts]\n",
    "    for file_path in file_paths:\n",
    "        with hdfs.open(file_path) as file:\n",
    "            dfs.append(pd.read_csv(file, **kwargs))\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections = read_csv('/user/datavirus/connections.csv')\n",
    "connections['start_time'] = ('2019-05-06 ' + connections['start_time']).astype('datetime64[ns]')\n",
    "connections['stop_time'] = ('2019-05-06 ' + connections['stop_time']).astype('datetime64[ns]')\n",
    "connections['delay_probability'] = connections['delay_probability'].round(3)\n",
    "connections['delay_parameter'] = connections['delay_parameter'].round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recover missing/incomplete line_text using other columns\n",
    "\n",
    "route_type_str = {\n",
    "    102: 'IC',\n",
    "    103: 'IR',\n",
    "    106: 'R',\n",
    "    400: 'S',\n",
    "    700: '',\n",
    "    900: '',\n",
    "}\n",
    "\n",
    "digits = tuple(map(str, range(10)))\n",
    "\n",
    "def line_text(row):\n",
    "    line_nr = ''.join([c for c in row['trip_id'].split('-')[1] if c in digits])\n",
    "    route_text = route_type_str[row['route_type']]\n",
    "    if row['transport_type'] != 'zug':\n",
    "        if row['line_text']:\n",
    "            return row['line_text']\n",
    "    elif row['line_text']:\n",
    "        line_text = str(row['line_text'])\n",
    "        has_line_nr = len([c for c in line_text if c in digits]) > 0\n",
    "        if has_line_nr:\n",
    "            return line_text\n",
    "        else:\n",
    "            return line_text + line_nr\n",
    "    return route_text + line_nr  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update line_text\n",
    "connections['line_text'] = connections['line_text'].fillna('')\n",
    "connections['line_text'] = connections.apply(line_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort connections in order required by connection scan algorithm\n",
    "connections = connections.sort_values(['stop_time', 'stop_sequence'], ascending=False)\n",
    "\n",
    "# retain only needed columns\n",
    "connections = connections.loc[:, ['start_id', 'start_time', 'trip_id', 'transport_type', 'line_text', 'stop_time', 'stop_id', 'delay_probability', 'delay_parameter']]\n",
    "\n",
    "# convert times to seconds\n",
    "connections['start_time'] = connections['start_time'].astype('int') // 10**9\n",
    "connections['stop_time'] = connections['stop_time'].astype('int') // 10**9\n",
    "\n",
    "connections = connections.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/connections.pickle', 'wb') as file:\n",
    "    pickle.dump(connections, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "connections_stations = set(connections['start_id']).union(connections['stop_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>station_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8502186</th>\n",
       "      <td>8502186</td>\n",
       "      <td>8.398942</td>\n",
       "      <td>47.393407</td>\n",
       "      <td>Dietikon Stoffelbach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502187</th>\n",
       "      <td>8502187</td>\n",
       "      <td>8.377032</td>\n",
       "      <td>47.364740</td>\n",
       "      <td>Rudolfstetten Hofacker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502188</th>\n",
       "      <td>8502188</td>\n",
       "      <td>8.354599</td>\n",
       "      <td>47.355907</td>\n",
       "      <td>Zufikon Hammergut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502208</th>\n",
       "      <td>8502208</td>\n",
       "      <td>8.589802</td>\n",
       "      <td>47.258748</td>\n",
       "      <td>Horgen Oberdorf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8502209</th>\n",
       "      <td>8502209</td>\n",
       "      <td>8.577633</td>\n",
       "      <td>47.276724</td>\n",
       "      <td>Oberrieden Dorf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            station_id       lat        lon            station_name\n",
       "station_id                                                         \n",
       "8502186        8502186  8.398942  47.393407    Dietikon Stoffelbach\n",
       "8502187        8502187  8.377032  47.364740  Rudolfstetten Hofacker\n",
       "8502188        8502188  8.354599  47.355907       Zufikon Hammergut\n",
       "8502208        8502208  8.589802  47.258748         Horgen Oberdorf\n",
       "8502209        8502209  8.577633  47.276724         Oberrieden Dorf"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.read_csv('../data/stations.csv')\n",
    "stations.columns = ['station_id', 'lat', 'lon', 'height', 'station_name', 'distance_from_zurich']\n",
    "stations = stations.set_index('station_id', drop=False)\n",
    "stations = stations.drop(['distance_from_zurich', 'height'], axis=1)\n",
    "stations = stations.loc[stations['station_id'].isin(connections_stations)]\n",
    "stations.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/stations.pickle', 'wb') as file:\n",
    "    pickle.dump(stations, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Footpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "footpaths = pd.read_csv('../data/footpaths.csv')\n",
    "footpaths.columns = ['start_id', 'start_lat', 'start_lon', 'start_height', 'stop_id', 'stop_lat', 'stop_lon', 'stop_height', 'height_difference', 'distance', 'speed', 'time']\n",
    "footpaths['time'] = footpaths['time'].astype(int)\n",
    "\n",
    "# remove cycles\n",
    "footpaths = footpaths[footpaths['start_id'] != footpaths['stop_id']]\n",
    "\n",
    "# remove unused stations\n",
    "footpaths = footpaths[\n",
    "    footpaths['start_id'].isin(connections_stations)\n",
    "    & footpaths['stop_id'].isin(connections_stations)\n",
    "]\n",
    "\n",
    "# retain only required columns\n",
    "footpaths = footpaths.loc[:, ['start_id', 'stop_id', 'time']]\n",
    "\n",
    "# create dictionary\n",
    "footpaths = {start_id: list(zip(*row)) for start_id, row in footpaths.groupby('start_id').agg(list).iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/footpaths.pickle', 'wb') as file:\n",
    "    pickle.dump(footpaths, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
